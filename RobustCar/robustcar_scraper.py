#!/usr/bin/env python3
"""
üöó RobustCar Scraper - Sistema de Extra√ß√£o de Estoque
Agente Respons√°vel: Data Analyst üìà

Este m√≥dulo extrai dados de carros do site robustcar.com.br
seguindo pr√°ticas √©ticas de web scraping e integra√ß√£o com
nosso framework de recomenda√ß√£o.
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import csv
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import List, Optional, Dict
import logging
from urllib.parse import urljoin, urlparse

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class CarData:
    """Estrutura padronizada dos dados do carro"""
    id: str
    nome: str
    marca: str
    modelo: str
    ano: int
    preco: float
    quilometragem: int
    combustivel: str
    cambio: str
    cor: str
    descricao: str
    imagens: List[str]
    url_original: str
    data_scraping: str
    disponivel: bool = True
    
    # Campos calculados para recomenda√ß√£o
    categoria: str = ""  # hatch, sedan, suv, etc.
    consumo_estimado: float = 0.0
    score_familia: float = 0.0
    score_economia: float = 0.0

class RobustCarScraper:
    """
    Scraper espec√≠fico para RobustCar com guardrails do AI Engineer
    """
    
    def __init__(self):
        self.base_url = "https://robustcar.com.br"
        self.search_url = "https://robustcar.com.br/busca//pag/{}/ordem/ano-desc/"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.carros_extraidos = []
        self.rate_limit_delay = 2  # segundos entre requests
        
    def verificar_robots_txt(self) -> bool:
        """Verificar se o scraping √© permitido pelo robots.txt"""
        try:
            robots_url = urljoin(self.base_url, '/robots.txt')
            response = self.session.get(robots_url)
            robots_content = response.text.lower()
            
            # Verificar se h√° restri√ß√µes espec√≠ficas
            if 'disallow: /busca' in robots_content:
                logger.warning("robots.txt pro√≠be acesso √† √°rea de busca")
                return False
                
            logger.info("robots.txt verificado - scraping permitido")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao verificar robots.txt: {e}")
            return True  # Continue se n√£o conseguir verificar
    
    def extrair_carros_pagina(self, pagina: int) -> List[CarData]:
        """Extrair carros de uma p√°gina espec√≠fica"""
        url = self.search_url.format(pagina)
        logger.info(f"Extraindo p√°gina {pagina}: {url}")
        
        try:
            response = self.session.get(url)
            response.raise_for_status()
            # Fix encoding issue
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            carros = []
            
            # Seletores espec√≠ficos para RobustCar baseado na an√°lise real
            car_listings = soup.find_all('div', class_='carro')
            
            if not car_listings:
                # Fallback para estrutura alternativa
                car_listings = soup.find_all('div', class_='card')
            
            logger.info(f"Encontrados {len(car_listings)} carros na p√°gina {pagina}")
            
            for i, car_element in enumerate(car_listings):
                try:
                    carro = self.extrair_dados_carro(car_element, pagina, i)
                    if carro:
                        carros.append(carro)
                        
                except Exception as e:
                    logger.error(f"Erro ao extrair carro {i} da p√°gina {pagina}: {e}")
                    continue
            
            return carros
            
        except Exception as e:
            logger.error(f"Erro ao acessar p√°gina {pagina}: {e}")
            return []
    
    def extrair_dados_carro(self, element, pagina: int, index: int) -> Optional[CarData]:
        """Extrair dados de um carro espec√≠fico"""
        try:
            # Seletores espec√≠ficos para RobustCar baseado na an√°lise real
            
            # Nome/T√≠tulo - baseado na an√°lise, est√° no link principal
            nome = ""
            
            # Tentar diferentes estrat√©gias para encontrar o nome
            # 1. Link principal com href de carros
            link_carros = element.find('a', href=lambda x: x and 'carros/' in x)
            if link_carros:
                nome = link_carros.get_text(strip=True)
            
            # 2. Se n√£o encontrou, tentar extrair do texto geral
            if not nome:
                full_text = element.get_text(strip=True)
                # O texto parece estar junto (ex: "2025CHEVROLET TRACKER T A LTFLEXPRATA...")
                # Vamos tentar separar por ano
                import re
                match = re.search(r'(\d{4})(.+)', full_text)
                if match:
                    ano_texto = match.group(1)
                    resto_texto = match.group(2)
                    # Tentar extrair marca e modelo
                    palavras = resto_texto.split()
                    if len(palavras) >= 2:
                        nome = f"{palavras[0]} {palavras[1]}"
                        if len(palavras) >= 3:
                            nome += f" {palavras[2]}"
            
            # 3. Fallback final
            if not nome:
                nome = f"Carro {pagina}-{index}"
            
            # Pre√ßo - estrutura espec√≠fica da RobustCar: h3.preco > span
            preco = 0.0
            
            # 1. Buscar h3.preco (estrutura real identificada)
            preco_h3 = element.find('h3', class_='preco')
            if preco_h3:
                # O valor est√° dentro do span
                span_valor = preco_h3.find('span')
                if span_valor:
                    preco_text = span_valor.get_text(strip=True)
                    preco = self.extrair_preco(preco_text)
                else:
                    # Fallback: pegar todo o texto do h3
                    preco_text = preco_h3.get_text(strip=True)
                    preco = self.extrair_preco(preco_text)
            
            # 2. Fallback: buscar div.preco (caso mudan√ßa futura)
            if preco == 0.0:
                preco_div = element.find('div', class_='preco')
                if preco_div:
                    preco_text = preco_div.get_text(strip=True)
                    preco = self.extrair_preco(preco_text)
            
            # 3. √öltimo fallback: buscar qualquer texto com valor monet√°rio
            if preco == 0.0:
                text_content = element.get_text()
                import re
                # Buscar padr√µes como "97.990,00" ou "R$ 97.990,00"
                preco_match = re.search(r'(\d{1,3}(?:\.\d{3})*,\d{2})', text_content)
                if preco_match:
                    preco = self.extrair_preco(preco_match.group(1))
            
            # Ano - extrair do nome ou buscar no texto
            ano = self.extrair_ano(nome)
            if ano == 2020:  # Se n√£o encontrou no nome, buscar no elemento
                text_content = element.get_text()
                ano = self.extrair_ano(text_content)
            
            # Quilometragem - buscar no texto do elemento
            text_content = element.get_text()
            quilometragem = self.extrair_quilometragem(text_content)
            
            # URL do carro
            link_element = element.find('a', href=True)
            url_carro = urljoin(self.base_url, link_element['href']) if link_element else ""
            
            # Imagens - RobustCar usa data-src para lazy loading
            img_elements = element.find_all('img')
            imagens = []
            for img in img_elements:
                src = img.get('data-src') or img.get('src')
                if src:
                    if src.startswith('http'):
                        imagens.append(src)
                    else:
                        imagens.append(urljoin(self.base_url, src))
            
            # Extrair marca e modelo do nome
            marca, modelo = self.extrair_marca_modelo(nome)
            
            # Criar ID √∫nico
            car_id = f"robust_{pagina}_{index}_{int(time.time())}"
            
            carro = CarData(
                id=car_id,
                nome=nome,
                marca=marca,
                modelo=modelo,
                ano=ano,
                preco=preco,
                quilometragem=quilometragem,
                combustivel=self.inferir_combustivel(nome),
                cambio=self.inferir_cambio(nome),
                cor=self.inferir_cor(nome),
                descricao=nome,
                imagens=imagens,
                url_original=url_carro,
                data_scraping=datetime.now().isoformat(),
                disponivel=True
            )
            
            # Calcular campos para recomenda√ß√£o (AI Engineer)
            carro = self.enriquecer_dados_ia(carro)
            
            return carro
            
        except Exception as e:
            logger.error(f"Erro ao extrair dados do carro: {e}")
            return None
    
    def extrair_preco(self, preco_text: str) -> float:
        """Extrair pre√ßo num√©rico do texto - formato brasileiro"""
        try:
            import re
            
            # Limpar texto de entrada
            texto_limpo = preco_text.replace('R$', '').replace(' ', '').strip()
            
            # Buscar padr√£o espec√≠fico brasileiro: 97.990,00
            match = re.search(r'(\d{1,3}(?:\.\d{3})*,\d{2})', texto_limpo)
            if match:
                preco_str = match.group(1)
                # Converter formato brasileiro para float
                # 97.990,00 ‚Üí 97990.00
                preco_str = preco_str.replace('.', '').replace(',', '.')
                return float(preco_str)
            
            # Fallback: buscar qualquer sequ√™ncia de n√∫meros
            numeros = re.findall(r'[\d.,]+', texto_limpo)
            if numeros:
                for numero in numeros:
                    try:
                        # Tentar interpretar como formato brasileiro
                        if ',' in numero and numero.count(',') == 1:
                            # Formato: 97.990,00 ou 97990,00
                            numero_convertido = numero.replace('.', '').replace(',', '.')
                            valor = float(numero_convertido)
                            if valor > 1000:  # Sanidade: pre√ßo m√≠nimo de carro
                                return valor
                    except:
                        continue
                        
        except Exception as e:
            logger.debug(f"Erro ao extrair pre√ßo '{preco_text}': {e}")
        
        return 0.0
    
    def extrair_ano(self, texto: str) -> int:
        """Extrair ano do texto"""
        try:
            import re
            anos = re.findall(r'20\d{2}', texto)
            if anos:
                return int(anos[0])
        except:
            pass
        return 2020
    
    def extrair_quilometragem(self, texto: str) -> int:
        """Extrair quilometragem do texto"""
        try:
            import re
            km_match = re.findall(r'(\d+(?:\.\d+)?)\s*km', texto.lower())
            if km_match:
                km_str = km_match[0].replace('.', '')
                return int(float(km_str))
        except:
            pass
        return 0
    
    def extrair_marca_modelo(self, nome: str) -> tuple:
        """Extrair marca e modelo do nome"""
        marcas_comuns = [
            'Toyota', 'Chevrolet', 'Volkswagen', 'Fiat', 'Honda', 'Hyundai',
            'Ford', 'Nissan', 'Peugeot', 'Renault', 'Citro√´n', 'Jeep',
            'BMW', 'Mercedes', 'Audi', 'Volvo', 'Mitsubishi', 'Kia'
        ]
        
        nome_upper = nome.upper()
        for marca in marcas_comuns:
            if marca.upper() in nome_upper:
                modelo = nome.replace(marca, '').strip()
                return marca, modelo
        
        # Se n√£o encontrar marca conhecida, usar primeira palavra como marca
        palavras = nome.split()
        if len(palavras) >= 2:
            return palavras[0], ' '.join(palavras[1:])
        
        return 'Gen√©rica', nome
    
    def inferir_combustivel(self, nome: str) -> str:
        """Inferir tipo de combust√≠vel baseado no nome"""
        nome_lower = nome.lower()
        if 'flex' in nome_lower:
            return 'Flex'
        elif 'diesel' in nome_lower:
            return 'Diesel'
        elif 'h√≠brido' in nome_lower or 'hybrid' in nome_lower:
            return 'H√≠brido'
        elif 'el√©trico' in nome_lower or 'electric' in nome_lower:
            return 'El√©trico'
        else:
            return 'Flex'  # Padr√£o brasileiro
    
    def inferir_cambio(self, nome: str) -> str:
        """Inferir tipo de c√¢mbio baseado no nome"""
        nome_lower = nome.lower()
        if 'autom√°tico' in nome_lower or 'auto' in nome_lower:
            return 'Autom√°tico'
        elif 'manual' in nome_lower:
            return 'Manual'
        else:
            return 'Manual'  # Padr√£o para carros usados
    
    def inferir_cor(self, nome: str) -> str:
        """Inferir cor baseado no nome (limitado)"""
        cores = {
            'branco': 'Branco', 'prata': 'Prata', 'preto': 'Preto',
            'azul': 'Azul', 'vermelho': 'Vermelho', 'cinza': 'Cinza'
        }
        
        nome_lower = nome.lower()
        for cor_key, cor_value in cores.items():
            if cor_key in nome_lower:
                return cor_value
        
        return 'N√£o informado'
    
    def enriquecer_dados_ia(self, carro: CarData) -> CarData:
        """Enriquecer dados com campos calculados para IA (AI Engineer)"""
        
        # Categorizar tipo de ve√≠culo
        nome_lower = carro.nome.lower()
        if any(term in nome_lower for term in ['suv', 'crossover']):
            carro.categoria = 'SUV'
        elif any(term in nome_lower for term in ['sedan', '4 portas']):
            carro.categoria = 'Sedan'
        elif any(term in nome_lower for term in ['hatch', 'hb']):
            carro.categoria = 'Hatch'
        elif any(term in nome_lower for term in ['pickup', 'cabine']):
            carro.categoria = 'Pickup'
        else:
            carro.categoria = 'Hatch'  # Padr√£o
        
        # Score para fam√≠lias (baseado em tipo e ano)
        if carro.categoria in ['SUV', 'Sedan']:
            carro.score_familia = 0.8
        elif carro.categoria == 'Hatch' and carro.ano >= 2018:
            carro.score_familia = 0.6
        else:
            carro.score_familia = 0.4
        
        # Score economia (baseado em ano, marca e categoria)
        economia_base = 0.5
        if carro.ano >= 2020:
            economia_base += 0.2
        if carro.marca.lower() in ['toyota', 'honda', 'hyundai']:
            economia_base += 0.2
        if carro.categoria == 'Hatch':
            economia_base += 0.1
        
        carro.score_economia = min(economia_base, 1.0)
        
        # Estimativa de consumo (aproximada)
        if carro.categoria == 'Hatch':
            carro.consumo_estimado = 12.5
        elif carro.categoria == 'Sedan':
            carro.consumo_estimado = 11.0
        elif carro.categoria == 'SUV':
            carro.consumo_estimado = 9.5
        else:
            carro.consumo_estimado = 10.0
        
        return carro
    
    def scraping_completo(self, max_paginas: int = 10) -> List[CarData]:
        """Executar scraping completo com guardrails"""
        
        if not self.verificar_robots_txt():
            logger.error("Scraping n√£o permitido pelo robots.txt")
            return []
        
        logger.info(f"Iniciando scraping da RobustCar - m√°ximo {max_paginas} p√°ginas")
        
        todos_carros = []
        paginas_vazias = 0
        
        for pagina in range(1, max_paginas + 1):
            carros_pagina = self.extrair_carros_pagina(pagina)
            
            if not carros_pagina:
                paginas_vazias += 1
                if paginas_vazias >= 3:  # Parar se 3 p√°ginas consecutivas vazias
                    logger.info(f"3 p√°ginas vazias consecutivas - parando scraping")
                    break
            else:
                paginas_vazias = 0
                todos_carros.extend(carros_pagina)
                logger.info(f"P√°gina {pagina}: {len(carros_pagina)} carros extra√≠dos")
            
            # Rate limiting para n√£o sobrecarregar o servidor
            time.sleep(self.rate_limit_delay)
        
        logger.info(f"Scraping conclu√≠do: {len(todos_carros)} carros extra√≠dos")
        self.carros_extraidos = todos_carros
        return todos_carros
    
    def salvar_dados(self, formato: str = 'json') -> str:
        """Salvar dados extra√≠dos"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if formato == 'json':
            filename = f"robustcar_estoque_{timestamp}.json"
            dados = [asdict(carro) for carro in self.carros_extraidos]
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(dados, f, ensure_ascii=False, indent=2)
                
        elif formato == 'csv':
            filename = f"robustcar_estoque_{timestamp}.csv"
            
            with open(filename, 'w', newline='', encoding='utf-8') as f:
                if self.carros_extraidos:
                    writer = csv.DictWriter(f, fieldnames=asdict(self.carros_extraidos[0]).keys())
                    writer.writeheader()
                    for carro in self.carros_extraidos:
                        writer.writerow(asdict(carro))
        
        logger.info(f"Dados salvos em: {filename}")
        return filename
    
    def gerar_relatorio_estoque(self) -> Dict:
        """Gerar relat√≥rio resumido do estoque"""
        if not self.carros_extraidos:
            return {}
        
        total_carros = len(self.carros_extraidos)
        preco_medio = sum(c.preco for c in self.carros_extraidos) / total_carros
        
        # An√°lise por marca
        marcas = {}
        for carro in self.carros_extraidos:
            marcas[carro.marca] = marcas.get(carro.marca, 0) + 1
        
        # An√°lise por categoria
        categorias = {}
        for carro in self.carros_extraidos:
            categorias[carro.categoria] = categorias.get(carro.categoria, 0) + 1
        
        # An√°lise por faixa de pre√ßo
        faixas_preco = {
            "at√© 30k": len([c for c in self.carros_extraidos if c.preco <= 30000]),
            "30k-50k": len([c for c in self.carros_extraidos if 30000 < c.preco <= 50000]),
            "50k-80k": len([c for c in self.carros_extraidos if 50000 < c.preco <= 80000]),
            "80k+": len([c for c in self.carros_extraidos if c.preco > 80000])
        }
        
        relatorio = {
            "total_carros": total_carros,
            "preco_medio": round(preco_medio, 2),
            "por_marca": marcas,
            "por_categoria": categorias,
            "por_faixa_preco": faixas_preco,
            "data_scraping": datetime.now().isoformat()
        }
        
        return relatorio

def main():
    """Fun√ß√£o principal para execu√ß√£o do scraper"""
    scraper = RobustCarScraper()
    
    print("üöó RobustCar Scraper - Iniciando...")
    print("="*50)
    
    # Executar scraping
    carros = scraper.scraping_completo(max_paginas=5)  # Come√ßar com 5 p√°ginas
    
    if carros:
        print(f"\n‚úÖ Scraping conclu√≠do: {len(carros)} carros extra√≠dos")
        
        # Salvar dados
        arquivo_json = scraper.salvar_dados('json')
        arquivo_csv = scraper.salvar_dados('csv')
        
        # Gerar relat√≥rio
        relatorio = scraper.gerar_relatorio_estoque()
        print(f"\nüìä Relat√≥rio do Estoque:")
        print(f"Total de carros: {relatorio['total_carros']}")
        print(f"Pre√ßo m√©dio: R$ {relatorio['preco_medio']:,.2f}")
        print(f"Marcas: {list(relatorio['por_marca'].keys())}")
        print(f"Categorias: {list(relatorio['por_categoria'].keys())}")
        
        print(f"\nüíæ Arquivos salvos:")
        print(f"- {arquivo_json}")
        print(f"- {arquivo_csv}")
        
    else:
        print("‚ùå Nenhum carro foi extra√≠do. Verifique a estrutura do site.")

if __name__ == "__main__":
    main()
