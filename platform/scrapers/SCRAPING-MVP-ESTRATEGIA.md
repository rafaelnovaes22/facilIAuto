# Estrat√©gia de Scraping para MVP

**Data**: 30/10/2025  
**Contexto**: Popular banco de dados rapidamente para MVP

---

## üéØ Objetivo

Obter dados de 2-3 concession√°rias para validar produto no MVP.

---

## üìä Status dos Scrapers

### 1. RobustCar
**Status**: ‚úÖ Funcional (HTML est√°tico)  
**M√©todo**: Scraping autom√°tico  
**Tempo**: ~5-10 minutos  
**Ve√≠culos**: ~70-90 carros

### 2. RP Multimarcas
**Status**: ‚ö†Ô∏è Site usa JavaScript  
**Problema**: Ve√≠culos carregados dinamicamente via JS  
**Solu√ß√µes**:

#### Op√ß√£o A: Selenium/Playwright (Autom√°tico)
```python
# Pros:
‚úÖ Totalmente autom√°tico
‚úÖ Funciona com JavaScript
‚úÖ Pode ser reutilizado

# Contras:
‚ùå Requer instala√ß√£o de browser driver
‚ùå Mais lento (5-10x)
‚ùå Mais complexo
‚ùå Pode quebrar facilmente

# Tempo estimado: 3-4 horas de implementa√ß√£o
```

#### Op√ß√£o B: Extra√ß√£o Manual + CSV (Recomendado para MVP)
```python
# Pros:
‚úÖ Muito r√°pido (30-60 minutos)
‚úÖ Simples e confi√°vel
‚úÖ Dados 100% precisos
‚úÖ N√£o quebra

# Contras:
‚ùå Trabalho manual
‚ùå N√£o escal√°vel

# Tempo estimado: 30-60 minutos
```

#### Op√ß√£o C: API/Feed (Ideal, mas improv√°vel)
```python
# Pros:
‚úÖ Dados estruturados
‚úÖ Sempre atualizado
‚úÖ Oficial

# Contras:
‚ùå Concession√°ria precisa fornecer
‚ùå Improv√°vel para MVP

# Tempo estimado: Depende da concession√°ria
```

---

## üöÄ Recomenda√ß√£o para MVP

### Use Op√ß√£o B: Extra√ß√£o Manual + CSV

**Por qu√™?**
1. **Tempo**: 30-60 minutos vs 3-4 horas
2. **Confiabilidade**: 100% vs ~70% (Selenium pode falhar)
3. **Simplicidade**: Copiar/colar vs c√≥digo complexo
4. **MVP**: Objetivo √© validar produto, n√£o ter scraping perfeito

**Como fazer:**

#### Passo 1: Criar Template CSV
```csv
nome,marca,modelo,ano,preco,quilometragem,combustivel,cambio,cor,portas,categoria,url_original
```

#### Passo 2: Abrir Site e Copiar Dados
1. Abrir https://rpmultimarcas.com.br/
2. Para cada ve√≠culo:
   - Copiar nome, pre√ßo, ano, km
   - Copiar caracter√≠sticas (c√¢mbio, combust√≠vel, etc.)
   - Colar na planilha

#### Passo 3: Importar CSV
```python
python import_csv_to_json.py rpmultimarcas.csv
```

**Tempo total**: 30-60 minutos para ~30-50 carros

---

## üìã Plano de A√ß√£o Imediato

### Para MVP (Hoje)

1. ‚úÖ **RobustCar**: Executar scraper autom√°tico
   ```bash
   python robustcar_scraper.py
   ```

2. ‚úÖ **RP Multimarcas**: Extra√ß√£o manual + CSV
   ```bash
   # Criar planilha manualmente
   # Importar com script
   python import_csv_to_json.py rpmultimarcas.csv
   ```

3. ‚úÖ **Importar no Backend**
   ```bash
   # Copiar JSONs para backend/data/
   cp robustcar_estoque.json ../backend/data/
   cp rpmultimarcas_estoque.json ../backend/data/
   ```

**Tempo total**: 1-2 horas  
**Resultado**: MVP com ~100-150 carros de 2 concession√°rias

### Para Produ√ß√£o (Fase 2)

1. üöÄ **Portal Self-Service**: Concession√°rias gerenciam pr√≥prio estoque
2. üöÄ **Eliminar scraping**: N√£o ser√° mais necess√°rio
3. üöÄ **Ver**: `docs/implementation/ROADMAP-GESTAO-ESTOQUE.md`

---

## üõ†Ô∏è Script de Importa√ß√£o CSV

Vou criar um script para facilitar a importa√ß√£o:

```python
# import_csv_to_json.py
import csv
import json
from datetime import datetime
import hashlib

def import_csv_to_json(csv_file, output_file):
    """Importar CSV para formato JSON do FacilIAuto"""
    
    vehicles = []
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            # Converter tipos
            vehicle = {
                'id': f"rpmulti_{len(vehicles) + 1}",
                'nome': row['nome'],
                'marca': row['marca'],
                'modelo': row['modelo'],
                'ano': int(row['ano']),
                'preco': float(row['preco']),
                'quilometragem': int(row['quilometragem']),
                'combustivel': row['combustivel'],
                'cambio': row['cambio'],
                'cor': row.get('cor'),
                'portas': int(row['portas']) if row.get('portas') else None,
                'categoria': row['categoria'],
                'url_original': row['url_original'],
                'data_scraping': datetime.now().isoformat()
            }
            
            # Calcular hash
            hashable = {k: v for k, v in vehicle.items() if k not in ['id', 'data_scraping']}
            vehicle['content_hash'] = hashlib.md5(
                json.dumps(hashable, sort_keys=True).encode()
            ).hexdigest()
            
            vehicles.append(vehicle)
    
    # Salvar JSON
    output = {
        'metadata': {
            'source': 'rpmultimarcas.com.br',
            'method': 'manual_csv_import',
            'timestamp': datetime.now().isoformat(),
            'total_vehicles': len(vehicles)
        },
        'vehicles': vehicles
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Importados {len(vehicles)} ve√≠culos")
    print(f"üíæ Salvo em: {output_file}")

if __name__ == '__main__':
    import sys
    if len(sys.argv) < 2:
        print("Uso: python import_csv_to_json.py <arquivo.csv>")
        sys.exit(1)
    
    csv_file = sys.argv[1]
    output_file = csv_file.replace('.csv', '_estoque.json')
    import_csv_to_json(csv_file, output_file)
```

---

## üìä Compara√ß√£o de M√©todos

| M√©todo | Tempo | Confiabilidade | Escalabilidade | Recomendado para |
|--------|-------|----------------|----------------|------------------|
| **Scraping HTML** | 10 min | Alta (90%) | M√©dia | Sites est√°ticos |
| **Selenium/Playwright** | 30-60 min | M√©dia (70%) | Baixa | Sites com JS simples |
| **Manual + CSV** | 30-60 min | Muito Alta (100%) | Muito Baixa | MVP r√°pido |
| **API/Feed** | 5 min | Muito Alta (100%) | Muito Alta | Produ√ß√£o |
| **Portal Self-Service** | N/A | Muito Alta (100%) | Muito Alta | Produ√ß√£o |

---

## ‚úÖ Decis√£o para MVP

### RobustCar
- ‚úÖ Usar scraper autom√°tico (j√° funciona)
- ‚úÖ Executar agora

### RP Multimarcas
- ‚úÖ Usar extra√ß√£o manual + CSV
- ‚úÖ Mais r√°pido e confi√°vel para MVP
- ‚úÖ Executar agora

### Pr√≥ximas Concession√°rias (se necess√°rio)
- ‚úÖ Avaliar caso a caso
- ‚úÖ Priorizar sites com HTML est√°tico
- ‚úÖ Usar manual + CSV se tiver JavaScript

---

## üéØ Pr√≥ximos Passos

1. **Agora**: Executar scraper RobustCar
2. **Agora**: Criar CSV RP Multimarcas (30-60 min)
3. **Agora**: Importar ambos no backend
4. **Depois**: Validar no frontend
5. **Futuro**: Implementar portal self-service (Fase 2)

---

**√öltima Atualiza√ß√£o**: 30/10/2025  
**Status**: Estrat√©gia definida, pronta para execu√ß√£o
