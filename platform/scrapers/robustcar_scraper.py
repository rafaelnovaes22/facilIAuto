"""
Scraper para RobustCar - Extra√ß√£o de dados de ve√≠culos
Corrigido para extrair c√¢mbio e quilometragem corretamente
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime
from typing import List, Dict, Optional
import time


class RobustCarScraper:
    """Scraper para o site RobustCar"""
    
    def __init__(self):
        self.base_url = "https://robustcar.com.br"
        # URL que funcionou anteriormente
        self.search_url_template = "https://robustcar.com.br/busca//pag/{}/ordem/ano-desc/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
    
    def extract_cambio(self, text: str) -> Optional[str]:
        """
        Extrair tipo de c√¢mbio do texto
        
        Padr√µes comuns:
        - "C√¢mbio: Manual"
        - "C√¢mbio: Autom√°tico"
        - "C√¢mbio: Autom√°tico CVT"
        - "M" ou "A" ou "CVT"
        
        IMPORTANTE: Retorna None se n√£o encontrar, N√ÉO assume valor padr√£o
        """
        if not text:
            return None  # N√£o assumir valor padr√£o
        
        text_lower = text.lower()
        
        # Padr√µes de autom√°tico
        if 'autom√°tico cvt' in text_lower or 'automatico cvt' in text_lower or 'cvt' in text_lower:
            return "Autom√°tico CVT"
        elif 'autom√°tico' in text_lower or 'automatico' in text_lower or 'automatic' in text_lower:
            return "Autom√°tico"
        elif 'automatizada' in text_lower:
            return "Automatizada"
        elif 'manual' in text_lower:
            return "Manual"
        
        # Padr√µes curtos
        if re.search(r'\bA\b', text):  # "A" isolado
            return "Autom√°tico"
        elif re.search(r'\bM\b', text):  # "M" isolado
            return "Manual"
        
        return None  # N√£o assumir valor padr√£o se n√£o encontrar
    
    def extract_quilometragem(self, text: str) -> int:
        """
        Extrair quilometragem do texto
        
        Padr√µes comuns:
        - "50.000 km"
        - "50000 km"
        - "50 mil km"
        - "0 km" ou "Zero km"
        """
        if not text:
            return 0
        
        text_lower = text.lower()
        
        # Zero km
        if 'zero km' in text_lower or '0 km' in text_lower or '0km' in text_lower:
            return 0
        
        # Padr√£o: n√∫meros seguidos de "km"
        # Ex: "50.000 km", "50000 km", "50,000 km"
        pattern = r'(\d+(?:[.,]\d+)*)\s*(?:mil\s+)?km'
        match = re.search(pattern, text_lower)
        
        if match:
            km_str = match.group(1)
            # Remover pontos e v√≠rgulas
            km_str = km_str.replace('.', '').replace(',', '')
            
            try:
                km = int(km_str)
                
                # Se tem "mil" no texto, multiplicar por 1000
                if 'mil' in text_lower and km < 1000:
                    km *= 1000
                
                return km
            except ValueError:
                return 0
        
        return 0
    
    def extract_car_details(self, car_url: str) -> Optional[Dict]:
        """
        Extrair detalhes de um carro espec√≠fico
        Dados est√£o na se√ß√£o "Resumo" com formato: Combust√≠vel FLEX Cor BRANCO KM 51.985 Ano Fab 2024 Ano Modelo 2025
        """
        try:
            response = self.session.get(car_url, timeout=15)
            response.raise_for_status()
            response.encoding = 'utf-8'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            car_data = {
                'url_original': car_url,
                'data_scraping': datetime.now().isoformat()
            }
            
            # Buscar se√ß√£o "Resumo" especificamente
            resumo_section = None
            
            # Estrat√©gia 1: Buscar por ID ou classe "resumo"
            resumo_section = (soup.find(id=re.compile(r'resumo', re.IGNORECASE)) or
                            soup.find(class_=re.compile(r'resumo', re.IGNORECASE)))
            
            # Estrat√©gia 2: Buscar por heading "Resumo" e pegar a se√ß√£o seguinte
            if not resumo_section:
                resumo_heading = soup.find(['h2', 'h3', 'h4'], string=re.compile(r'resumo', re.IGNORECASE))
                if resumo_heading:
                    resumo_section = resumo_heading.find_next(['div', 'section', 'ul'])
            
            # Se encontrou a se√ß√£o Resumo, extrair texto dela
            if resumo_section:
                resumo_text = resumo_section.get_text()
            else:
                # Fallback: usar texto completo da p√°gina
                resumo_text = soup.get_text()
            
            # Extrair nome/t√≠tulo - geralmente em h1
            title = soup.find('h1')
            if title:
                # O t√≠tulo pode conter ano + marca + modelo (ex: "2025 RENAULT KWID ZEN 2")
                title_text = title.text.strip()
                car_data['nome'] = title_text
                
                # Extrair ano do t√≠tulo se presente
                ano_match = re.search(r'^(\d{4})\s+', title_text)
                if ano_match:
                    car_data['ano'] = int(ano_match.group(1))
                    # Remover ano do nome para extrair marca/modelo
                    nome_sem_ano = title_text.replace(ano_match.group(0), '').strip()
                else:
                    nome_sem_ano = title_text
                
                # Extrair marca e modelo
                nome_parts = nome_sem_ano.split()
                if len(nome_parts) >= 2:
                    car_data['marca'] = nome_parts[0].title()
                    car_data['modelo'] = ' '.join(nome_parts[1:])
            
            # Extrair pre√ßo - buscar logo ap√≥s o t√≠tulo (topo da p√°gina)
            # Padr√£o: "R$ 62.990,00"
            page_text = soup.get_text()
            
            # Buscar pre√ßo pr√≥ximo ao t√≠tulo
            price_match = re.search(r'R\$\s*([\d.,]+)', page_text)
            if price_match:
                price_str = price_match.group(1)
                # Normalizar formato brasileiro: 62.990,00 -> 62990.00
                price_str = price_str.replace('.', '').replace(',', '.')
                try:
                    price_value = float(price_str)
                    if 10000 <= price_value <= 500000:
                        car_data['preco'] = price_value
                except ValueError:
                    pass
            
            # Padr√£o espec√≠fico RobustCar: "Combust√≠vel FLEX"
            combustivel_match = re.search(r'Combust√≠vel\s+(\w+)', resumo_text, re.IGNORECASE)
            if combustivel_match:
                comb = combustivel_match.group(1).strip()
                if 'flex' in comb.lower():
                    car_data['combustivel'] = 'Flex'
                elif 'gasolina' in comb.lower():
                    car_data['combustivel'] = 'Gasolina'
                elif 'diesel' in comb.lower():
                    car_data['combustivel'] = 'Diesel'
                elif 'eletrico' in comb.lower() or 'el√©trico' in comb.lower():
                    car_data['combustivel'] = 'El√©trico'
            
            # Padr√£o espec√≠fico RobustCar: "Cor BRANCO"
            cor_match = re.search(r'Cor\s+([A-Z√Ä-√ö\s]+?)(?:Placa|KM|Ano|\n)', resumo_text, re.IGNORECASE)
            if cor_match:
                car_data['cor'] = cor_match.group(1).strip().title()
            
            # Padr√£o espec√≠fico RobustCar: "KM 51.985"
            km_match = re.search(r'KM\s+([\d.,]+)', resumo_text, re.IGNORECASE)
            if km_match:
                km_str = km_match.group(1).replace('.', '').replace(',', '')
                try:
                    km_value = int(km_str)
                    if 0 <= km_value <= 500000:
                        car_data['quilometragem'] = km_value
                except ValueError:
                    pass
            
            # Padr√£o espec√≠fico RobustCar: "Ano Fab 2024 Ano Modelo 2025"
            # Priorizar Ano Modelo
            ano_modelo_match = re.search(r'Ano\s+Modelo\s+(\d{4})', resumo_text, re.IGNORECASE)
            if ano_modelo_match:
                car_data['ano'] = int(ano_modelo_match.group(1))
            else:
                # Fallback: Ano Fab
                ano_fab_match = re.search(r'Ano\s+Fab\s+(\d{4})', resumo_text, re.IGNORECASE)
                if ano_fab_match:
                    car_data['ano'] = int(ano_fab_match.group(1))
            
                # Buscar se√ß√£o "Opcionais do Ve√≠culo" para extrair c√¢mbio
            opcionais_section = None
            
            # Estrat√©gia 1: Buscar por heading "Opcionais" (com encoding correto)
            opcionais_heading = soup.find(['h2', 'h3', 'h4', 'h5'], string=re.compile(r'opcionais', re.IGNORECASE))
            if opcionais_heading:
                opcionais_section = opcionais_heading.find_next(['div', 'section', 'ul'])
            
            # Estrat√©gia 2: Buscar por classe
            if not opcionais_section:
                opcionais_section = soup.find(class_=re.compile(r'opcionais', re.IGNORECASE))
            
            # Extrair c√¢mbio da se√ß√£o de opcionais
            if opcionais_section:
                opcionais_text = opcionais_section.get_text()
                
                # Normalizar texto para lidar com encoding issues
                # Remover espa√ßos extras e normalizar
                opcionais_text_clean = ' '.join(opcionais_text.split())
                
                # Buscar "C√¢mbio Manual" ou "C√¢mbio Autom√°tico" (com varia√ß√µes de encoding)
                # Aceitar: c√¢mbio, cambio, cÔøΩmbio
                if re.search(r'c[√¢aÔøΩ]mbio\s+autom[√°aÔøΩ]tico', opcionais_text_clean, re.IGNORECASE):
                    if 'cvt' in opcionais_text_clean.lower():
                        car_data['cambio'] = 'Autom√°tico CVT'
                    else:
                        car_data['cambio'] = 'Autom√°tico'
                elif re.search(r'c[√¢aÔøΩ]mbio\s+manual', opcionais_text_clean, re.IGNORECASE):
                    car_data['cambio'] = 'Manual'
            
            # Fallback 1: buscar c√¢mbio no nome do ve√≠culo (ex: "AUT.", "MT", "MEC")
            if 'cambio' not in car_data and 'nome' in car_data:
                nome_upper = car_data['nome'].upper()
                
                # Padr√µes comuns no nome: AUT., AUT, AT, AUTOM√ÅTICO
                if re.search(r'\bAUT\.?\b|\bAT\b|AUTOM[√ÅA]TICO', nome_upper):
                    if 'CVT' in nome_upper:
                        car_data['cambio'] = 'Autom√°tico CVT'
                    else:
                        car_data['cambio'] = 'Autom√°tico'
                # Padr√µes manuais: MT, MEC, MANUAL
                elif re.search(r'\bMT\b|\bMEC\.?\b|MANUAL', nome_upper):
                    car_data['cambio'] = 'Manual'
            
            # Fallback 2: buscar c√¢mbio no texto geral se ainda n√£o encontrou
            if 'cambio' not in car_data:
                # Normalizar texto da p√°gina
                page_text_clean = ' '.join(page_text.split())
                
                # Buscar padr√µes mais espec√≠ficos primeiro
                cambio_match = re.search(r'c[√¢aÔøΩ]mbio[:\s]+([a-z√°√†√¢√£√©√™√≠√≥√¥√µ√∫√ß\s]+?)(?:\n|Cor|KM|Ano|Placa)', page_text_clean, re.IGNORECASE)
                if cambio_match:
                    cambio_text = cambio_match.group(1).strip().lower()
                    if 'autom' in cambio_text:
                        if 'cvt' in cambio_text:
                            car_data['cambio'] = 'Autom√°tico CVT'
                        else:
                            car_data['cambio'] = 'Autom√°tico'
                    elif 'manual' in cambio_text:
                        car_data['cambio'] = 'Manual'
                # Fallback gen√©rico
                elif re.search(r'autom[√°aÔøΩ]tico', page_text_clean, re.IGNORECASE):
                    if 'cvt' in page_text_clean.lower():
                        car_data['cambio'] = 'Autom√°tico CVT'
                    else:
                        car_data['cambio'] = 'Autom√°tico'
                elif 'manual' in page_text_clean.lower():
                    car_data['cambio'] = 'Manual'
            
            # Extrair imagens - RobustCar usa data-src para lazy loading
            images = []
            for img in soup.find_all('img'):
                src = img.get('data-src') or img.get('src', '')
                if src and ('carro57' in src or 'robustcar' in src):
                    if src.startswith('http'):
                        images.append(src)
                    elif src.startswith('/'):
                        images.append(self.base_url + src)
            
            if images:
                car_data['imagens'] = list(set(images))[:10]  # Remover duplicatas, m√°ximo 10
            
            # Inferir categoria baseado no nome
            if 'nome' in car_data:
                nome_lower = car_data['nome'].lower()
                if any(term in nome_lower for term in ['suv', 'crossover', 'tracker', 'creta', 'compass', 'renegade']):
                    car_data['categoria'] = 'SUV'
                elif any(term in nome_lower for term in ['sedan', 'cruze', 'civic', 'corolla', 'hb20s']):
                    car_data['categoria'] = 'Sedan'
                elif any(term in nome_lower for term in ['hatch', 'onix', 'hb20', 'gol']):
                    car_data['categoria'] = 'Hatch'
                elif any(term in nome_lower for term in ['pickup', 'strada', 'saveiro', 'montana']):
                    car_data['categoria'] = 'Pickup'
                elif any(term in nome_lower for term in ['mobi', 'up', 'kwid']):
                    car_data['categoria'] = 'Compacto'
            
            return car_data
            
        except Exception as e:
            print(f"      ‚ùå Erro ao extrair detalhes: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def scrape_listing_page(self, page: int = 1) -> List[str]:
        """
        Extrair URLs de carros da p√°gina de busca
        Usando URL que funcionou anteriormente
        """
        try:
            # URL que funcionou: /busca//pag/{}/ordem/ano-desc/
            page_url = self.search_url_template.format(page)
            
            print(f"   Acessando: {page_url}")
            response = self.session.get(page_url, timeout=15)
            response.raise_for_status()
            response.encoding = 'utf-8'  # Fix encoding
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Seletores espec√≠ficos que funcionaram
            urls = set()
            
            # Estrat√©gia 1: Buscar div.carro (seletor espec√≠fico do RobustCar)
            car_divs = soup.find_all('div', class_='carro')
            print(f"   Encontrados {len(car_divs)} div.carro")
            
            for car_div in car_divs:
                link = car_div.find('a', href=True)
                if link:
                    href = link.get('href', '')
                    if href:
                        if href.startswith('http'):
                            urls.add(href)
                        elif href.startswith('/'):
                            urls.add(self.base_url + href)
            
            # Estrat√©gia 2: Fallback para div.card
            if not urls:
                card_divs = soup.find_all('div', class_='card')
                print(f"   Fallback: Encontrados {len(card_divs)} div.card")
                
                for card_div in card_divs:
                    link = card_div.find('a', href=True)
                    if link:
                        href = link.get('href', '')
                        if href and '/carros/' in href:
                            if href.startswith('http'):
                                urls.add(href)
                            elif href.startswith('/'):
                                urls.add(self.base_url + href)
            
            return list(urls)
            
        except Exception as e:
            print(f"   ‚ùå Erro ao extrair listagem: {e}")
            return []
    
    def scrape_all(self, max_pages: int = 3) -> List[Dict]:
        """
        Fazer scraping de m√∫ltiplas p√°ginas
        """
        all_cars = []
        all_urls = set()
        
        print(f"\nüîç Iniciando scraping do RobustCar...")
        print(f"Site: {self.base_url}")
        print(f"P√°ginas a processar: {max_pages}")
        
        # Coletar URLs de todas as p√°ginas primeiro
        for page in range(1, max_pages + 1):
            print(f"\nüìÑ Coletando URLs da p√°gina {page}...")
            
            car_urls = self.scrape_listing_page(page)
            
            if not car_urls:
                print(f"   ‚ö†Ô∏è  Nenhuma URL encontrada, parando...")
                break
            
            print(f"   Encontrados {len(car_urls)} URLs")
            all_urls.update(car_urls)
            
            # Delay entre p√°ginas
            time.sleep(2)
        
        print(f"\nüìä Total de URLs √∫nicas coletadas: {len(all_urls)}")
        
        if not all_urls:
            print("\n‚ö†Ô∏è  Nenhum ve√≠culo encontrado")
            print("   Poss√≠veis causas:")
            print("   1. Site usa JavaScript para carregar ve√≠culos")
            print("   2. Seletores CSS precisam ser ajustados")
            print("   3. Site est√° temporariamente indispon√≠vel")
            return []
        
        # Extrair detalhes de cada ve√≠culo
        for i, car_url in enumerate(sorted(all_urls), 1):
            print(f"\n   [{i}/{len(all_urls)}] Processando...")
            print(f"   URL: {car_url}")
            
            car_data = self.extract_car_details(car_url)
            
            if car_data:
                # Validar campos obrigat√≥rios
                required_fields = ['nome', 'preco', 'ano', 'quilometragem']
                missing_fields = [f for f in required_fields if f not in car_data]
                
                if missing_fields:
                    print(f"      ‚ö†Ô∏è  Campos obrigat√≥rios faltando: {missing_fields}")
                    print(f"      ‚ö†Ô∏è  Ve√≠culo ser√° rejeitado")
                else:
                    all_cars.append(car_data)
                    print(f"      ‚úÖ {car_data.get('nome', 'N/A')}")
                    print(f"         Pre√ßo: R$ {car_data.get('preco', 0):,.2f}")
                    print(f"         Ano: {car_data.get('ano', 'N/A')}")
                    print(f"         KM: {car_data.get('quilometragem', 'N/A'):,}")
            else:
                print(f"      ‚ùå Falha ao extrair dados")
            
            # Delay para n√£o sobrecarregar o servidor
            time.sleep(2)
        
        print(f"\n‚úÖ Scraping conclu√≠do: {len(all_cars)} carros v√°lidos de {len(all_urls)} URLs")
        
        return all_cars
    
    def validate_car_data(self, car: Dict) -> List[str]:
        """
        Validar dados extra√≠dos
        """
        warnings = []
        
        # Validar campos obrigat√≥rios
        required_fields = ['nome', 'preco', 'ano']
        for field in required_fields:
            if field not in car or not car[field]:
                warnings.append(f"Campo obrigat√≥rio ausente: {field}")
        
        # Validar c√¢mbio
        if 'cambio' in car:
            valid_cambios = ['Manual', 'Autom√°tico', 'Autom√°tico CVT', 'Automatizada']
            if car['cambio'] not in valid_cambios:
                warnings.append(f"C√¢mbio inv√°lido: {car['cambio']}")
        else:
            warnings.append("C√¢mbio n√£o extra√≠do")
        
        # Validar quilometragem
        if 'quilometragem' not in car:
            warnings.append("Quilometragem n√£o extra√≠da")
        elif car['quilometragem'] == 0 and car.get('ano', 2025) < 2024:
            warnings.append(f"Carro de {car.get('ano')} com 0km √© suspeito")
        
        # Validar pre√ßo
        if 'preco' in car and car['preco'] <= 0:
            warnings.append("Pre√ßo inv√°lido")
        
        return warnings
    
    def save_to_json(self, cars: List[Dict], filename: str):
        """
        Salvar dados em JSON
        """
        # Validar todos os carros
        print(f"\nüîç Validando {len(cars)} carros...")
        
        total_warnings = 0
        for car in cars:
            warnings = self.validate_car_data(car)
            if warnings:
                total_warnings += len(warnings)
                print(f"\n‚ö†Ô∏è  {car.get('nome', 'N/A')}:")
                for warning in warnings:
                    print(f"   - {warning}")
        
        if total_warnings == 0:
            print("‚úÖ Todos os carros validados com sucesso!")
        else:
            print(f"\n‚ö†Ô∏è  Total de avisos: {total_warnings}")
        
        # Salvar
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(cars, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ Dados salvos em: {filename}")


def main():
    """Fun√ß√£o principal"""
    scraper = RobustCarScraper()
    
    # Fazer scraping - 5 p√°ginas para pegar ~100 ve√≠culos
    cars = scraper.scrape_all(max_pages=5)
    
    # Salvar
    if cars:
        scraper.save_to_json(cars, 'robustcar_estoque_new.json')
    else:
        print("\n‚ùå Nenhum carro extra√≠do")


if __name__ == "__main__":
    main()
