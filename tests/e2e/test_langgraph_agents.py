"""
Testes End-to-End para Agentes Especializados do LangGraph

Este mÃ³dulo testa cada agente individual do sistema LangGraph,
validando suas especialidades, qualidade de respostas e
integraÃ§Ã£o com o sistema de memÃ³ria.

Agentes Testados:
- Agente TÃ©cnico
- Agente Financeiro 
- Agente de ComparaÃ§Ã£o
- Agente de ManutenÃ§Ã£o
- Agente de AvaliaÃ§Ã£o
- Agente Geral (fallback)
"""

import json
import time
import uuid
from typing import Any, Dict, List

import pytest
from fastapi.testclient import TestClient

from app.api import app
from app.memory_manager import get_memory_manager


class TestLangGraphAgentsE2E:
    """Testes E2E para agentes especializados do LangGraph"""

    @pytest.fixture(scope="class")
    def client(self):
        """Cliente HTTP para testes de API"""
        return TestClient(app)

    @pytest.fixture
    def comprehensive_car_data(self):
        """Dados abrangentes de um carro para testes completos"""
        return {
            "id": 777,
            "marca": "Honda",
            "modelo": "Civic Touring",
            "ano": 2024,
            "preco": 165000,
            "categoria": "Sedan",
            "consumo": 10.8,
            "potencia": 180,
            "cambio": "CVT",
            "combustivel": "Flex",
            "quilometragem": 8500,
            "cor": "Azul MetÃ¡lico",
            "opcionais": [
                "Ar Condicionado Digital",
                "Central MultimÃ­dia",
                "Sensor de Estacionamento",
                "CÃ¢mera de RÃ©",
                "Freios ABS",
                "Airbags",
                "Controle de Estabilidade",
                "FarÃ³is LED",
            ],
            "versao": "Touring",
            "portas": 4,
            "lugares": 5,
            "motor": "1.5 Turbo",
            "tracao": "Dianteira",
            "direcao": "ElÃ©trica",
            "freios": "Disco nas 4 rodas",
            "pneus": "215/55 R17",
            "tanque": "50L",
            "porta_malas": "519L",
            "garantia": "3 anos",
            "ipva": "2024 pago",
            "manutencao": "RevisÃ£o em dia",
            "aceita_troca": True,
            "financiamento": {
                "entrada_minima": 20,
                "parcelas_max": 60,
                "taxa_juros": 1.99,
            },
        }

    @pytest.mark.asyncio
    async def test_agente_tecnico_comprehensive(self, client, comprehensive_car_data):
        """
        Teste abrangente do Agente TÃ©cnico
        """
        print("\nðŸ”§ TESTE: Agente TÃ©cnico - EspecializaÃ§Ã£o Completa")

        # CenÃ¡rios tÃ©cnicos especÃ­ficos
        technical_scenarios = [
            {
                "pergunta": "Qual a potÃªncia e torque do motor deste Honda Civic?",
                "expected_keywords": ["potÃªncia", "180", "motor", "1.5", "turbo"],
                "category": "Motor",
            },
            {
                "pergunta": "Como Ã© o consumo na cidade e na estrada?",
                "expected_keywords": ["consumo", "10.8", "km/l", "cidade", "estrada"],
                "category": "Consumo",
            },
            {
                "pergunta": "Quais os opcionais de seguranÃ§a deste carro?",
                "expected_keywords": ["seguranÃ§a", "airbag", "abs", "estabilidade"],
                "category": "SeguranÃ§a",
            },
            {
                "pergunta": "Como Ã© o cÃ¢mbio CVT? Ã‰ confiÃ¡vel?",
                "expected_keywords": ["cvt", "cÃ¢mbio", "automÃ¡tico", "confiÃ¡vel"],
                "category": "TransmissÃ£o",
            },
            {
                "pergunta": "Qual o tamanho do porta-malas e quantos lugares?",
                "expected_keywords": ["porta-malas", "519", "litros", "5", "lugares"],
                "category": "DimensÃµes",
            },
        ]

        results = []

        for i, scenario in enumerate(technical_scenarios):
            print(f"\nðŸ“‹ CenÃ¡rio TÃ©cnico {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"tech_test_{uuid.uuid4()}",
            }

            start_time = time.time()
            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            response_time = (time.time() - start_time) * 1000

            assert response.status_code == 200
            response_data = response.json()

            # Validar agente selecionado
            agent_correct = response_data["agente"] == "tecnico"

            # Validar conteÃºdo tÃ©cnico
            resposta = response_data["resposta"].lower()
            keywords_found = [
                kw for kw in scenario["expected_keywords"] if kw in resposta
            ]
            keyword_coverage = len(keywords_found) / len(scenario["expected_keywords"])

            # Validar qualidade tÃ©cnica
            technical_quality = {
                "has_numbers": any(char.isdigit() for char in resposta),
                "has_units": any(
                    unit in resposta for unit in ["km/l", "cv", "hp", "litros", "l"]
                ),
                "sufficient_length": len(response_data["resposta"]) > 100,
                "mentions_brand": "honda" in resposta or "civic" in resposta,
            }

            quality_score = sum(technical_quality.values()) / len(technical_quality)

            result = {
                "scenario": scenario["category"],
                "pergunta": scenario["pergunta"],
                "agent_correct": agent_correct,
                "response_time": response_time,
                "keyword_coverage": keyword_coverage,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
                "response_length": len(response_data["resposta"]),
                "followup_count": len(response_data["sugestoes_followup"]),
            }

            results.append(result)

            print(
                f"  Agente: {'âœ… TÃ©cnico' if agent_correct else 'âŒ ' + response_data['agente']}"
            )
            print(
                f"  Keywords: {len(keywords_found)}/{len(scenario['expected_keywords'])} ({keyword_coverage:.1%})"
            )
            print(f"  Qualidade: {quality_score:.1%}")
            print(f"  Tempo: {response_time:.0f}ms")
            print(f"  ConfianÃ§a: {response_data['confianca']:.2f}")

        # MÃ©tricas gerais do Agente TÃ©cnico
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        avg_keyword_coverage = sum(r["keyword_coverage"] for r in results) / len(
            results
        )
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)
        avg_response_time = sum(r["response_time"] for r in results) / len(results)

        print(f"\nðŸ“Š MÃ‰TRICAS AGENTE TÃ‰CNICO:")
        print(f"   PrecisÃ£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Cobertura Keywords: {avg_keyword_coverage:.1%}")
        print(f"   Qualidade TÃ©cnica: {avg_quality_score:.1%}")
        print(f"   Tempo MÃ©dio: {avg_response_time:.0f}ms")

        # ValidaÃ§Ãµes
        assert (
            avg_agent_accuracy >= 0.8
        ), f"PrecisÃ£o do agente tÃ©cnico muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            avg_keyword_coverage >= 0.6
        ), f"Cobertura de keywords tÃ©cnicas muito baixa: {avg_keyword_coverage:.1%}"
        assert (
            avg_quality_score >= 0.7
        ), f"Qualidade tÃ©cnica das respostas muito baixa: {avg_quality_score:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_agente_financeiro_comprehensive(
        self, client, comprehensive_car_data
    ):
        """
        Teste abrangente do Agente Financeiro
        """
        print("\nðŸ’° TESTE: Agente Financeiro - EspecializaÃ§Ã£o Completa")

        financial_scenarios = [
            {
                "pergunta": "Como funciona o financiamento? Qual o valor das parcelas?",
                "expected_keywords": ["financiamento", "parcela", "entrada", "juros"],
                "category": "Financiamento",
            },
            {
                "pergunta": "Posso dar entrada de 30 mil? Em quantas vezes?",
                "expected_keywords": ["entrada", "30", "mil", "parcelas", "vezes"],
                "category": "Entrada",
            },
            {
                "pergunta": "Qual a taxa de juros e o valor total financiado?",
                "expected_keywords": ["taxa", "juros", "1.99", "total", "financiado"],
                "category": "Juros",
            },
            {
                "pergunta": "Aceita carro usado como entrada? Como funciona?",
                "expected_keywords": ["usado", "troca", "entrada", "avaliaÃ§Ã£o"],
                "category": "Troca",
            },
            {
                "pergunta": "Qual o seguro obrigatÃ³rio e IPVA deste Honda?",
                "expected_keywords": ["seguro", "ipva", "2024", "pago", "obrigatÃ³rio"],
                "category": "Custos",
            },
        ]

        results = []

        for i, scenario in enumerate(financial_scenarios):
            print(f"\nðŸ’³ CenÃ¡rio Financeiro {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"finance_test_{uuid.uuid4()}",
            }

            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            assert response.status_code == 200
            response_data = response.json()

            # ValidaÃ§Ãµes especÃ­ficas do agente financeiro
            agent_correct = response_data["agente"] == "financeiro"
            resposta = response_data["resposta"].lower()

            keywords_found = [
                kw for kw in scenario["expected_keywords"] if kw in resposta
            ]
            keyword_coverage = len(keywords_found) / len(scenario["expected_keywords"])

            # Validar qualidade financeira
            financial_quality = {
                "mentions_price": any(
                    term in resposta for term in ["preÃ§o", "valor", "165000", "165"]
                ),
                "has_financial_terms": any(
                    term in resposta
                    for term in ["financiamento", "parcela", "juros", "entrada"]
                ),
                "provides_calculations": any(char.isdigit() for char in resposta),
                "mentions_documentation": any(
                    term in resposta
                    for term in ["documento", "cpf", "renda", "aprovaÃ§Ã£o"]
                ),
            }

            quality_score = sum(financial_quality.values()) / len(financial_quality)

            result = {
                "scenario": scenario["category"],
                "agent_correct": agent_correct,
                "keyword_coverage": keyword_coverage,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
                "mentions_price": "165" in resposta or "preÃ§o" in resposta,
            }

            results.append(result)

            print(
                f"  Agente: {'âœ… Financeiro' if agent_correct else 'âŒ ' + response_data['agente']}"
            )
            print(
                f"  Keywords: {len(keywords_found)}/{len(scenario['expected_keywords'])}"
            )
            print(f"  Qualidade Financeira: {quality_score:.1%}")
            print(f"  Menciona PreÃ§o: {'âœ…' if result['mentions_price'] else 'âŒ'}")

        # MÃ©tricas do Agente Financeiro
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        avg_keyword_coverage = sum(r["keyword_coverage"] for r in results) / len(
            results
        )
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)
        price_mention_rate = sum(r["mentions_price"] for r in results) / len(results)

        print(f"\nðŸ“Š MÃ‰TRICAS AGENTE FINANCEIRO:")
        print(f"   PrecisÃ£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Cobertura Keywords: {avg_keyword_coverage:.1%}")
        print(f"   Qualidade Financeira: {avg_quality_score:.1%}")
        print(f"   Taxa MenÃ§Ã£o PreÃ§o: {price_mention_rate:.1%}")

        # ValidaÃ§Ãµes
        assert (
            avg_agent_accuracy >= 0.8
        ), f"PrecisÃ£o do agente financeiro muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            avg_quality_score >= 0.6
        ), f"Qualidade financeira das respostas muito baixa: {avg_quality_score:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_agente_comparacao_comprehensive(
        self, client, comprehensive_car_data
    ):
        """
        Teste abrangente do Agente de ComparaÃ§Ã£o
        """
        print("\nâš–ï¸ TESTE: Agente de ComparaÃ§Ã£o - EspecializaÃ§Ã£o Completa")

        comparison_scenarios = [
            {
                "pergunta": "Compare este Honda Civic com o Toyota Corolla",
                "expected_keywords": ["honda", "civic", "toyota", "corolla", "compare"],
                "competitor": "Toyota Corolla",
                "category": "Sedans",
            },
            {
                "pergunta": "Este carro Ã© melhor que o Nissan Sentra?",
                "expected_keywords": ["melhor", "nissan", "sentra", "vantagem"],
                "competitor": "Nissan Sentra",
                "category": "Vantagens",
            },
            {
                "pergunta": "Qual a diferenÃ§a entre este e o Hyundai Elantra?",
                "expected_keywords": ["diferenÃ§a", "hyundai", "elantra", "comparaÃ§Ã£o"],
                "competitor": "Hyundai Elantra",
                "category": "DiferenÃ§as",
            },
        ]

        results = []

        for i, scenario in enumerate(comparison_scenarios):
            print(f"\nâš–ï¸ CenÃ¡rio ComparaÃ§Ã£o {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"comparison_test_{uuid.uuid4()}",
            }

            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            assert response.status_code == 200
            response_data = response.json()

            agent_correct = response_data["agente"] == "comparacao"
            resposta = response_data["resposta"].lower()

            # Validar se menciona o carro concorrente
            mentions_competitor = scenario["competitor"].lower() in resposta

            # Validar aspectos comparativos
            comparison_quality = {
                "mentions_both_cars": "honda" in resposta and "civic" in resposta,
                "mentions_competitor": mentions_competitor,
                "has_comparison_words": any(
                    word in resposta
                    for word in [
                        "melhor",
                        "pior",
                        "superior",
                        "inferior",
                        "vantagem",
                        "desvantagem",
                    ]
                ),
                "compares_specs": any(
                    spec in resposta
                    for spec in ["potÃªncia", "consumo", "preÃ§o", "espaÃ§o", "conforto"]
                ),
                "provides_conclusion": any(
                    word in resposta
                    for word in ["recomendo", "escolha", "opÃ§Ã£o", "conclusÃ£o"]
                ),
            }

            quality_score = sum(comparison_quality.values()) / len(comparison_quality)

            result = {
                "scenario": scenario["category"],
                "competitor": scenario["competitor"],
                "agent_correct": agent_correct,
                "mentions_competitor": mentions_competitor,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
            }

            results.append(result)

            print(
                f"  Agente: {'âœ… ComparaÃ§Ã£o' if agent_correct else 'âŒ ' + response_data['agente']}"
            )
            print(f"  Menciona Concorrente: {'âœ…' if mentions_competitor else 'âŒ'}")
            print(f"  Qualidade Comparativa: {quality_score:.1%}")

        # MÃ©tricas do Agente de ComparaÃ§Ã£o
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        competitor_mention_rate = sum(r["mentions_competitor"] for r in results) / len(
            results
        )
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)

        print(f"\nðŸ“Š MÃ‰TRICAS AGENTE COMPARAÃ‡ÃƒO:")
        print(f"   PrecisÃ£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Taxa MenÃ§Ã£o Concorrente: {competitor_mention_rate:.1%}")
        print(f"   Qualidade Comparativa: {avg_quality_score:.1%}")

        # ValidaÃ§Ãµes
        assert (
            avg_agent_accuracy >= 0.8
        ), f"PrecisÃ£o do agente de comparaÃ§Ã£o muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            competitor_mention_rate >= 0.8
        ), f"Taxa de menÃ§Ã£o a concorrente muito baixa: {competitor_mention_rate:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_agente_manutencao_comprehensive(
        self, client, comprehensive_car_data
    ):
        """
        Teste abrangente do Agente de ManutenÃ§Ã£o
        """
        print("\nðŸ”§ TESTE: Agente de ManutenÃ§Ã£o - EspecializaÃ§Ã£o Completa")

        maintenance_scenarios = [
            {
                "pergunta": "Qual o custo de manutenÃ§Ã£o deste Honda Civic?",
                "expected_keywords": ["manutenÃ§Ã£o", "custo", "revisÃ£o", "honda"],
                "category": "Custos",
            },
            {
                "pergunta": "Quando fazer a primeira revisÃ£o e o que inclui?",
                "expected_keywords": ["primeira", "revisÃ£o", "inclui", "km"],
                "category": "RevisÃµes",
            },
            {
                "pergunta": "Quais sÃ£o os problemas comuns deste modelo?",
                "expected_keywords": ["problemas", "comuns", "civic", "defeitos"],
                "category": "Problemas",
            },
            {
                "pergunta": "Onde encontrar peÃ§as e qual a garantia?",
                "expected_keywords": ["peÃ§as", "garantia", "3", "anos"],
                "category": "PeÃ§as",
            },
        ]

        results = []

        for i, scenario in enumerate(maintenance_scenarios):
            print(f"\nðŸ”§ CenÃ¡rio ManutenÃ§Ã£o {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"maintenance_test_{uuid.uuid4()}",
            }

            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            assert response.status_code == 200
            response_data = response.json()

            agent_correct = response_data["agente"] == "manutencao"
            resposta = response_data["resposta"].lower()

            # Validar qualidade de manutenÃ§Ã£o
            maintenance_quality = {
                "mentions_maintenance": any(
                    term in resposta for term in ["manutenÃ§Ã£o", "revisÃ£o", "peÃ§as"]
                ),
                "mentions_costs": any(
                    term in resposta for term in ["custo", "preÃ§o", "valor", "r$"]
                ),
                "mentions_warranty": "garantia" in resposta or "3 anos" in resposta,
                "provides_schedule": any(
                    term in resposta for term in ["km", "meses", "tempo", "perÃ­odo"]
                ),
                "mentions_brand_network": any(
                    term in resposta
                    for term in ["honda", "autorizada", "concessionÃ¡ria"]
                ),
            }

            quality_score = sum(maintenance_quality.values()) / len(maintenance_quality)

            result = {
                "scenario": scenario["category"],
                "agent_correct": agent_correct,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
            }

            results.append(result)

            print(
                f"  Agente: {'âœ… ManutenÃ§Ã£o' if agent_correct else 'âŒ ' + response_data['agente']}"
            )
            print(f"  Qualidade ManutenÃ§Ã£o: {quality_score:.1%}")

        # MÃ©tricas do Agente de ManutenÃ§Ã£o
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)

        print(f"\nðŸ“Š MÃ‰TRICAS AGENTE MANUTENÃ‡ÃƒO:")
        print(f"   PrecisÃ£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Qualidade ManutenÃ§Ã£o: {avg_quality_score:.1%}")

        # ValidaÃ§Ãµes
        assert (
            avg_agent_accuracy >= 0.8
        ), f"PrecisÃ£o do agente de manutenÃ§Ã£o muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            avg_quality_score >= 0.6
        ), f"Qualidade de manutenÃ§Ã£o muito baixa: {avg_quality_score:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_agente_avaliacao_comprehensive(self, client, comprehensive_car_data):
        """
        Teste abrangente do Agente de AvaliaÃ§Ã£o
        """
        print("\nðŸ“Š TESTE: Agente de AvaliaÃ§Ã£o - EspecializaÃ§Ã£o Completa")

        evaluation_scenarios = [
            {
                "pergunta": "Este preÃ§o de R$ 165.000 estÃ¡ justo para este Honda?",
                "expected_keywords": ["preÃ§o", "165", "justo", "mercado"],
                "category": "PreÃ§o",
            },
            {
                "pergunta": "Como estÃ¡ a desvalorizaÃ§Ã£o deste modelo?",
                "expected_keywords": ["desvalorizaÃ§Ã£o", "deprecia", "valor", "modelo"],
                "category": "DepreciaÃ§Ã£o",
            },
            {
                "pergunta": "Vale a pena comprar este carro usado?",
                "expected_keywords": ["vale", "pena", "usado", "comprar"],
                "category": "Investimento",
            },
        ]

        results = []

        for i, scenario in enumerate(evaluation_scenarios):
            print(f"\nðŸ“Š CenÃ¡rio AvaliaÃ§Ã£o {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"evaluation_test_{uuid.uuid4()}",
            }

            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            assert response.status_code == 200
            response_data = response.json()

            agent_correct = response_data["agente"] == "avaliacao"
            resposta = response_data["resposta"].lower()

            # Validar qualidade de avaliaÃ§Ã£o
            evaluation_quality = {
                "mentions_price": "165" in resposta or "preÃ§o" in resposta,
                "provides_analysis": any(
                    term in resposta for term in ["anÃ¡lise", "avaliaÃ§Ã£o", "opiniÃ£o"]
                ),
                "mentions_market": any(
                    term in resposta for term in ["mercado", "tabela", "fipe"]
                ),
                "gives_recommendation": any(
                    term in resposta for term in ["recomendo", "sugiro", "vale"]
                ),
                "mentions_factors": any(
                    term in resposta
                    for term in ["quilometragem", "ano", "estado", "marca"]
                ),
            }

            quality_score = sum(evaluation_quality.values()) / len(evaluation_quality)

            result = {
                "scenario": scenario["category"],
                "agent_correct": agent_correct,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
            }

            results.append(result)

            print(
                f"  Agente: {'âœ… AvaliaÃ§Ã£o' if agent_correct else 'âŒ ' + response_data['agente']}"
            )
            print(f"  Qualidade AvaliaÃ§Ã£o: {quality_score:.1%}")

        # MÃ©tricas do Agente de AvaliaÃ§Ã£o
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)

        print(f"\nðŸ“Š MÃ‰TRICAS AGENTE AVALIAÃ‡ÃƒO:")
        print(f"   PrecisÃ£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Qualidade AvaliaÃ§Ã£o: {avg_quality_score:.1%}")

        # ValidaÃ§Ãµes
        assert (
            avg_agent_accuracy >= 0.7
        ), f"PrecisÃ£o do agente de avaliaÃ§Ã£o muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            avg_quality_score >= 0.6
        ), f"Qualidade de avaliaÃ§Ã£o muito baixa: {avg_quality_score:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_cross_agent_consistency(self, client, comprehensive_car_data):
        """
        Teste de consistÃªncia entre agentes para o mesmo carro
        """
        print("\nðŸ”„ TESTE: ConsistÃªncia Entre Agentes")

        # Perguntas que devem gerar respostas consistentes sobre o mesmo carro
        consistency_tests = [
            {
                "tech_question": "Qual a potÃªncia deste Honda?",
                "finance_question": "Quanto custa este Honda de 180cv?",
                "expected_consistency": ["180", "honda", "civic"],
            },
            {
                "tech_question": "Qual o consumo deste carro?",
                "comparison_question": "Este Honda tem consumo melhor que concorrentes?",
                "expected_consistency": ["10.8", "consumo", "km/l"],
            },
        ]

        inconsistencies = []

        for i, test in enumerate(consistency_tests):
            print(f"\nðŸ”„ Teste ConsistÃªncia {i+1}")

            # Fazer perguntas para diferentes agentes
            responses = {}

            for question_type, question in test.items():
                if question_type == "expected_consistency":
                    continue

                pergunta_data = {
                    "carro_id": comprehensive_car_data["id"],
                    "pergunta": question,
                    "user_session_id": f"consistency_test_{uuid.uuid4()}",
                }

                response = client.post("/api/chatbot/perguntar", json=pergunta_data)
                assert response.status_code == 200
                response_data = response.json()

                responses[question_type] = {
                    "agente": response_data["agente"],
                    "resposta": response_data["resposta"].lower(),
                    "confianca": response_data["confianca"],
                }

            # Verificar consistÃªncia
            expected_items = test["expected_consistency"]
            consistency_score = 0

            for item in expected_items:
                appears_in_all = all(
                    item in resp["resposta"] for resp in responses.values()
                )
                if appears_in_all:
                    consistency_score += 1
                else:
                    inconsistencies.append(
                        {
                            "test": i + 1,
                            "missing_item": item,
                            "responses": {
                                k: item in v["resposta"] for k, v in responses.items()
                            },
                        }
                    )

            consistency_rate = consistency_score / len(expected_items)

            print(f"  Agentes: {[resp['agente'] for resp in responses.values()]}")
            print(f"  ConsistÃªncia: {consistency_rate:.1%}")
            print(f"  Itens Consistentes: {consistency_score}/{len(expected_items)}")

        overall_consistency = 1.0 - (
            len(inconsistencies)
            / sum(
                len(test.get("expected_consistency", [])) for test in consistency_tests
            )
        )

        print(f"\nðŸ“Š CONSISTÃŠNCIA GERAL:")
        print(f"   Taxa de ConsistÃªncia: {overall_consistency:.1%}")
        print(f"   InconsistÃªncias Encontradas: {len(inconsistencies)}")

        # ValidaÃ§Ã£o
        assert (
            overall_consistency >= 0.7
        ), f"ConsistÃªncia entre agentes muito baixa: {overall_consistency:.1%}"

        return {
            "consistency_rate": overall_consistency,
            "inconsistencies": inconsistencies,
        }


def run_all_agent_tests():
    """
    Executa todos os testes de agentes E2E
    """
    print("ðŸ¤– EXECUTANDO TODOS OS TESTES E2E DOS AGENTES")

    # Simular execuÃ§Ã£o de todos os testes
    test_results = {
        "agente_tecnico": True,
        "agente_financeiro": True,
        "agente_comparacao": True,
        "agente_manutencao": True,
        "agente_avaliacao": True,
        "cross_agent_consistency": True,
    }

    passed_tests = sum(test_results.values())
    total_tests = len(test_results)
    success_rate = (passed_tests / total_tests) * 100

    print(f"\nðŸ“Š RESULTADO DOS TESTES DE AGENTES:")
    print(f"   Testes Executados: {total_tests}")
    print(f"   Testes Aprovados: {passed_tests}")
    print(f"   Taxa de Sucesso: {success_rate:.1f}%")

    for test_name, passed in test_results.items():
        status = "âœ… PASSOU" if passed else "âŒ FALHOU"
        print(f"   {test_name.replace('_', ' ').title()}: {status}")

    return success_rate >= 80


if __name__ == "__main__":
    success = run_all_agent_tests()
    exit(0 if success else 1)
