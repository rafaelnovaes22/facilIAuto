"""
Testes End-to-End para Agentes Especializados do LangGraph

Este m√≥dulo testa cada agente individual do sistema LangGraph,
validando suas especialidades, qualidade de respostas e
integra√ß√£o com o sistema de mem√≥ria.

Agentes Testados:
- Agente T√©cnico
- Agente Financeiro 
- Agente de Compara√ß√£o
- Agente de Manuten√ß√£o
- Agente de Avalia√ß√£o
- Agente Geral (fallback)
"""

import json
import time
import uuid
from typing import Any, Dict, List

import pytest
from fastapi.testclient import TestClient

from app.api import app
from app.memory_manager import get_memory_manager


class TestLangGraphAgentsE2E:
    """Testes E2E para agentes especializados do LangGraph"""

    @pytest.fixture(scope="class")
    def client(self):
        """Cliente HTTP para testes de API"""
        return TestClient(app)

    @pytest.fixture
    def comprehensive_car_data(self):
        """Dados abrangentes de um carro para testes completos"""
        return {
            "id": 777,
            "marca": "Honda",
            "modelo": "Civic Touring",
            "ano": 2024,
            "preco": 165000,
            "categoria": "Sedan",
            "consumo": 10.8,
            "potencia": 180,
            "cambio": "CVT",
            "combustivel": "Flex",
            "quilometragem": 8500,
            "cor": "Azul Met√°lico",
            "opcionais": [
                "Ar Condicionado Digital",
                "Central Multim√≠dia",
                "Sensor de Estacionamento",
                "C√¢mera de R√©",
                "Freios ABS",
                "Airbags",
                "Controle de Estabilidade",
                "Far√≥is LED",
            ],
            "versao": "Touring",
            "portas": 4,
            "lugares": 5,
            "motor": "1.5 Turbo",
            "tracao": "Dianteira",
            "direcao": "El√©trica",
            "freios": "Disco nas 4 rodas",
            "pneus": "215/55 R17",
            "tanque": "50L",
            "porta_malas": "519L",
            "garantia": "3 anos",
            "ipva": "2024 pago",
            "manutencao": "Revis√£o em dia",
            "aceita_troca": True,
            "financiamento": {
                "entrada_minima": 20,
                "parcelas_max": 60,
                "taxa_juros": 1.99,
            },
        }

    @pytest.mark.asyncio
    async def test_agente_tecnico_comprehensive(self, client, comprehensive_car_data):
        """
        Teste abrangente do Agente T√©cnico
        """
        print("\nüîß TESTE: Agente T√©cnico - Especializa√ß√£o Completa")

        # Cen√°rios t√©cnicos espec√≠ficos
        technical_scenarios = [
            {
                "pergunta": "Qual a pot√™ncia e torque do motor deste Honda Civic?",
                "expected_keywords": ["pot√™ncia", "180", "motor", "1.5", "turbo"],
                "category": "Motor",
            },
            {
                "pergunta": "Como √© o consumo na cidade e na estrada?",
                "expected_keywords": ["consumo", "10.8", "km/l", "cidade", "estrada"],
                "category": "Consumo",
            },
            {
                "pergunta": "Quais os opcionais de seguran√ßa deste carro?",
                "expected_keywords": ["seguran√ßa", "airbag", "abs", "estabilidade"],
                "category": "Seguran√ßa",
            },
            {
                "pergunta": "Como √© o c√¢mbio CVT? √â confi√°vel?",
                "expected_keywords": ["cvt", "c√¢mbio", "autom√°tico", "confi√°vel"],
                "category": "Transmiss√£o",
            },
            {
                "pergunta": "Qual o tamanho do porta-malas e quantos lugares?",
                "expected_keywords": ["porta-malas", "519", "litros", "5", "lugares"],
                "category": "Dimens√µes",
            },
        ]

        results = []

        for i, scenario in enumerate(technical_scenarios):
            print(f"\nüìã Cen√°rio T√©cnico {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"tech_test_{uuid.uuid4()}",
            }

            start_time = time.time()
            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            response_time = (time.time() - start_time) * 1000

            assert response.status_code == 200
            response_data = response.json()

            # Validar agente selecionado
            agent_correct = response_data["agente"] == "tecnico"

            # Validar conte√∫do t√©cnico
            resposta = response_data["resposta"].lower()
            keywords_found = [
                kw for kw in scenario["expected_keywords"] if kw in resposta
            ]
            keyword_coverage = len(keywords_found) / len(scenario["expected_keywords"])

            # Validar qualidade t√©cnica
            technical_quality = {
                "has_numbers": any(char.isdigit() for char in resposta),
                "has_units": any(
                    unit in resposta for unit in ["km/l", "cv", "hp", "litros", "l"]
                ),
                "sufficient_length": len(response_data["resposta"]) > 100,
                "mentions_brand": "honda" in resposta or "civic" in resposta,
            }

            quality_score = sum(technical_quality.values()) / len(technical_quality)

            result = {
                "scenario": scenario["category"],
                "pergunta": scenario["pergunta"],
                "agent_correct": agent_correct,
                "response_time": response_time,
                "keyword_coverage": keyword_coverage,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
                "response_length": len(response_data["resposta"]),
                "followup_count": len(response_data["sugestoes_followup"]),
            }

            results.append(result)

            print(
                f"  Agente: {'‚úÖ T√©cnico' if agent_correct else '‚ùå ' + response_data['agente']}"
            )
            print(
                f"  Keywords: {len(keywords_found)}/{len(scenario['expected_keywords'])} ({keyword_coverage:.1%})"
            )
            print(f"  Qualidade: {quality_score:.1%}")
            print(f"  Tempo: {response_time:.0f}ms")
            print(f"  Confian√ßa: {response_data['confianca']:.2f}")

        # M√©tricas gerais do Agente T√©cnico
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        avg_keyword_coverage = sum(r["keyword_coverage"] for r in results) / len(
            results
        )
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)
        avg_response_time = sum(r["response_time"] for r in results) / len(results)

        print(f"\nüìä M√âTRICAS AGENTE T√âCNICO:")
        print(f"   Precis√£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Cobertura Keywords: {avg_keyword_coverage:.1%}")
        print(f"   Qualidade T√©cnica: {avg_quality_score:.1%}")
        print(f"   Tempo M√©dio: {avg_response_time:.0f}ms")

        # Valida√ß√µes
        assert (
            avg_agent_accuracy >= 0.8
        ), f"Precis√£o do agente t√©cnico muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            avg_keyword_coverage >= 0.6
        ), f"Cobertura de keywords t√©cnicas muito baixa: {avg_keyword_coverage:.1%}"
        assert (
            avg_quality_score >= 0.7
        ), f"Qualidade t√©cnica das respostas muito baixa: {avg_quality_score:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_agente_financeiro_comprehensive(
        self, client, comprehensive_car_data
    ):
        """
        Teste abrangente do Agente Financeiro
        """
        print("\nüí∞ TESTE: Agente Financeiro - Especializa√ß√£o Completa")

        financial_scenarios = [
            {
                "pergunta": "Como funciona o financiamento? Qual o valor das parcelas?",
                "expected_keywords": ["financiamento", "parcela", "entrada", "juros"],
                "category": "Financiamento",
            },
            {
                "pergunta": "Posso dar entrada de 30 mil? Em quantas vezes?",
                "expected_keywords": ["entrada", "30", "mil", "parcelas", "vezes"],
                "category": "Entrada",
            },
            {
                "pergunta": "Qual a taxa de juros e o valor total financiado?",
                "expected_keywords": ["taxa", "juros", "1.99", "total", "financiado"],
                "category": "Juros",
            },
            {
                "pergunta": "Aceita carro usado como entrada? Como funciona?",
                "expected_keywords": ["usado", "troca", "entrada", "avalia√ß√£o"],
                "category": "Troca",
            },
            {
                "pergunta": "Qual o seguro obrigat√≥rio e IPVA deste Honda?",
                "expected_keywords": ["seguro", "ipva", "2024", "pago", "obrigat√≥rio"],
                "category": "Custos",
            },
        ]

        results = []

        for i, scenario in enumerate(financial_scenarios):
            print(f"\nüí≥ Cen√°rio Financeiro {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"finance_test_{uuid.uuid4()}",
            }

            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            assert response.status_code == 200
            response_data = response.json()

            # Valida√ß√µes espec√≠ficas do agente financeiro
            agent_correct = response_data["agente"] == "financeiro"
            resposta = response_data["resposta"].lower()

            keywords_found = [
                kw for kw in scenario["expected_keywords"] if kw in resposta
            ]
            keyword_coverage = len(keywords_found) / len(scenario["expected_keywords"])

            # Validar qualidade financeira
            financial_quality = {
                "mentions_price": any(
                    term in resposta for term in ["pre√ßo", "valor", "165000", "165"]
                ),
                "has_financial_terms": any(
                    term in resposta
                    for term in ["financiamento", "parcela", "juros", "entrada"]
                ),
                "provides_calculations": any(char.isdigit() for char in resposta),
                "mentions_documentation": any(
                    term in resposta
                    for term in ["documento", "cpf", "renda", "aprova√ß√£o"]
                ),
            }

            quality_score = sum(financial_quality.values()) / len(financial_quality)

            result = {
                "scenario": scenario["category"],
                "agent_correct": agent_correct,
                "keyword_coverage": keyword_coverage,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
                "mentions_price": "165" in resposta or "pre√ßo" in resposta,
            }

            results.append(result)

            print(
                f"  Agente: {'‚úÖ Financeiro' if agent_correct else '‚ùå ' + response_data['agente']}"
            )
            print(
                f"  Keywords: {len(keywords_found)}/{len(scenario['expected_keywords'])}"
            )
            print(f"  Qualidade Financeira: {quality_score:.1%}")
            print(f"  Menciona Pre√ßo: {'‚úÖ' if result['mentions_price'] else '‚ùå'}")

        # M√©tricas do Agente Financeiro
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        avg_keyword_coverage = sum(r["keyword_coverage"] for r in results) / len(
            results
        )
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)
        price_mention_rate = sum(r["mentions_price"] for r in results) / len(results)

        print(f"\nüìä M√âTRICAS AGENTE FINANCEIRO:")
        print(f"   Precis√£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Cobertura Keywords: {avg_keyword_coverage:.1%}")
        print(f"   Qualidade Financeira: {avg_quality_score:.1%}")
        print(f"   Taxa Men√ß√£o Pre√ßo: {price_mention_rate:.1%}")

        # Valida√ß√µes
        assert (
            avg_agent_accuracy >= 0.8
        ), f"Precis√£o do agente financeiro muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            avg_quality_score >= 0.6
        ), f"Qualidade financeira das respostas muito baixa: {avg_quality_score:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_agente_comparacao_comprehensive(
        self, client, comprehensive_car_data
    ):
        """
        Teste abrangente do Agente de Compara√ß√£o
        """
        print("\n‚öñÔ∏è TESTE: Agente de Compara√ß√£o - Especializa√ß√£o Completa")

        comparison_scenarios = [
            {
                "pergunta": "Compare este Honda Civic com o Toyota Corolla",
                "expected_keywords": ["honda", "civic", "toyota", "corolla", "compare"],
                "competitor": "Toyota Corolla",
                "category": "Sedans",
            },
            {
                "pergunta": "Este carro √© melhor que o Nissan Sentra?",
                "expected_keywords": ["melhor", "nissan", "sentra", "vantagem"],
                "competitor": "Nissan Sentra",
                "category": "Vantagens",
            },
            {
                "pergunta": "Qual a diferen√ßa entre este e o Hyundai Elantra?",
                "expected_keywords": ["diferen√ßa", "hyundai", "elantra", "compara√ß√£o"],
                "competitor": "Hyundai Elantra",
                "category": "Diferen√ßas",
            },
        ]

        results = []

        for i, scenario in enumerate(comparison_scenarios):
            print(f"\n‚öñÔ∏è Cen√°rio Compara√ß√£o {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"comparison_test_{uuid.uuid4()}",
            }

            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            assert response.status_code == 200
            response_data = response.json()

            agent_correct = response_data["agente"] == "comparacao"
            resposta = response_data["resposta"].lower()

            # Validar se menciona o carro concorrente
            mentions_competitor = scenario["competitor"].lower() in resposta

            # Validar aspectos comparativos
            comparison_quality = {
                "mentions_both_cars": "honda" in resposta and "civic" in resposta,
                "mentions_competitor": mentions_competitor,
                "has_comparison_words": any(
                    word in resposta
                    for word in [
                        "melhor",
                        "pior",
                        "superior",
                        "inferior",
                        "vantagem",
                        "desvantagem",
                    ]
                ),
                "compares_specs": any(
                    spec in resposta
                    for spec in ["pot√™ncia", "consumo", "pre√ßo", "espa√ßo", "conforto"]
                ),
                "provides_conclusion": any(
                    word in resposta
                    for word in ["recomendo", "escolha", "op√ß√£o", "conclus√£o"]
                ),
            }

            quality_score = sum(comparison_quality.values()) / len(comparison_quality)

            result = {
                "scenario": scenario["category"],
                "competitor": scenario["competitor"],
                "agent_correct": agent_correct,
                "mentions_competitor": mentions_competitor,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
            }

            results.append(result)

            print(
                f"  Agente: {'‚úÖ Compara√ß√£o' if agent_correct else '‚ùå ' + response_data['agente']}"
            )
            print(f"  Menciona Concorrente: {'‚úÖ' if mentions_competitor else '‚ùå'}")
            print(f"  Qualidade Comparativa: {quality_score:.1%}")

        # M√©tricas do Agente de Compara√ß√£o
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        competitor_mention_rate = sum(r["mentions_competitor"] for r in results) / len(
            results
        )
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)

        print(f"\nüìä M√âTRICAS AGENTE COMPARA√á√ÉO:")
        print(f"   Precis√£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Taxa Men√ß√£o Concorrente: {competitor_mention_rate:.1%}")
        print(f"   Qualidade Comparativa: {avg_quality_score:.1%}")

        # Valida√ß√µes
        assert (
            avg_agent_accuracy >= 0.8
        ), f"Precis√£o do agente de compara√ß√£o muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            competitor_mention_rate >= 0.8
        ), f"Taxa de men√ß√£o a concorrente muito baixa: {competitor_mention_rate:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_agente_manutencao_comprehensive(
        self, client, comprehensive_car_data
    ):
        """
        Teste abrangente do Agente de Manuten√ß√£o
        """
        print("\nüîß TESTE: Agente de Manuten√ß√£o - Especializa√ß√£o Completa")

        maintenance_scenarios = [
            {
                "pergunta": "Qual o custo de manuten√ß√£o deste Honda Civic?",
                "expected_keywords": ["manuten√ß√£o", "custo", "revis√£o", "honda"],
                "category": "Custos",
            },
            {
                "pergunta": "Quando fazer a primeira revis√£o e o que inclui?",
                "expected_keywords": ["primeira", "revis√£o", "inclui", "km"],
                "category": "Revis√µes",
            },
            {
                "pergunta": "Quais s√£o os problemas comuns deste modelo?",
                "expected_keywords": ["problemas", "comuns", "civic", "defeitos"],
                "category": "Problemas",
            },
            {
                "pergunta": "Onde encontrar pe√ßas e qual a garantia?",
                "expected_keywords": ["pe√ßas", "garantia", "3", "anos"],
                "category": "Pe√ßas",
            },
        ]

        results = []

        for i, scenario in enumerate(maintenance_scenarios):
            print(f"\nüîß Cen√°rio Manuten√ß√£o {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"maintenance_test_{uuid.uuid4()}",
            }

            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            assert response.status_code == 200
            response_data = response.json()

            agent_correct = response_data["agente"] == "manutencao"
            resposta = response_data["resposta"].lower()

            # Validar qualidade de manuten√ß√£o
            maintenance_quality = {
                "mentions_maintenance": any(
                    term in resposta for term in ["manuten√ß√£o", "revis√£o", "pe√ßas"]
                ),
                "mentions_costs": any(
                    term in resposta for term in ["custo", "pre√ßo", "valor", "r$"]
                ),
                "mentions_warranty": "garantia" in resposta or "3 anos" in resposta,
                "provides_schedule": any(
                    term in resposta for term in ["km", "meses", "tempo", "per√≠odo"]
                ),
                "mentions_brand_network": any(
                    term in resposta
                    for term in ["honda", "autorizada", "concession√°ria"]
                ),
            }

            quality_score = sum(maintenance_quality.values()) / len(maintenance_quality)

            result = {
                "scenario": scenario["category"],
                "agent_correct": agent_correct,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
            }

            results.append(result)

            print(
                f"  Agente: {'‚úÖ Manuten√ß√£o' if agent_correct else '‚ùå ' + response_data['agente']}"
            )
            print(f"  Qualidade Manuten√ß√£o: {quality_score:.1%}")

        # M√©tricas do Agente de Manuten√ß√£o
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)

        print(f"\nüìä M√âTRICAS AGENTE MANUTEN√á√ÉO:")
        print(f"   Precis√£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Qualidade Manuten√ß√£o: {avg_quality_score:.1%}")

        # Valida√ß√µes
        assert (
            avg_agent_accuracy >= 0.8
        ), f"Precis√£o do agente de manuten√ß√£o muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            avg_quality_score >= 0.6
        ), f"Qualidade de manuten√ß√£o muito baixa: {avg_quality_score:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_agente_avaliacao_comprehensive(self, client, comprehensive_car_data):
        """
        Teste abrangente do Agente de Avalia√ß√£o
        """
        print("\nüìä TESTE: Agente de Avalia√ß√£o - Especializa√ß√£o Completa")

        evaluation_scenarios = [
            {
                "pergunta": "Este pre√ßo de R$ 165.000 est√° justo para este Honda?",
                "expected_keywords": ["pre√ßo", "165", "justo", "mercado"],
                "category": "Pre√ßo",
            },
            {
                "pergunta": "Como est√° a desvaloriza√ß√£o deste modelo?",
                "expected_keywords": ["desvaloriza√ß√£o", "deprecia", "valor", "modelo"],
                "category": "Deprecia√ß√£o",
            },
            {
                "pergunta": "Vale a pena comprar este carro usado?",
                "expected_keywords": ["vale", "pena", "usado", "comprar"],
                "category": "Investimento",
            },
        ]

        results = []

        for i, scenario in enumerate(evaluation_scenarios):
            print(f"\nüìä Cen√°rio Avalia√ß√£o {i+1}: {scenario['category']}")

            pergunta_data = {
                "carro_id": comprehensive_car_data["id"],
                "pergunta": scenario["pergunta"],
                "user_session_id": f"evaluation_test_{uuid.uuid4()}",
            }

            response = client.post("/api/chatbot/perguntar", json=pergunta_data)
            assert response.status_code == 200
            response_data = response.json()

            agent_correct = response_data["agente"] == "avaliacao"
            resposta = response_data["resposta"].lower()

            # Validar qualidade de avalia√ß√£o
            evaluation_quality = {
                "mentions_price": "165" in resposta or "pre√ßo" in resposta,
                "provides_analysis": any(
                    term in resposta for term in ["an√°lise", "avalia√ß√£o", "opini√£o"]
                ),
                "mentions_market": any(
                    term in resposta for term in ["mercado", "tabela", "fipe"]
                ),
                "gives_recommendation": any(
                    term in resposta for term in ["recomendo", "sugiro", "vale"]
                ),
                "mentions_factors": any(
                    term in resposta
                    for term in ["quilometragem", "ano", "estado", "marca"]
                ),
            }

            quality_score = sum(evaluation_quality.values()) / len(evaluation_quality)

            result = {
                "scenario": scenario["category"],
                "agent_correct": agent_correct,
                "quality_score": quality_score,
                "confidence": response_data["confianca"],
            }

            results.append(result)

            print(
                f"  Agente: {'‚úÖ Avalia√ß√£o' if agent_correct else '‚ùå ' + response_data['agente']}"
            )
            print(f"  Qualidade Avalia√ß√£o: {quality_score:.1%}")

        # M√©tricas do Agente de Avalia√ß√£o
        avg_agent_accuracy = sum(r["agent_correct"] for r in results) / len(results)
        avg_quality_score = sum(r["quality_score"] for r in results) / len(results)

        print(f"\nüìä M√âTRICAS AGENTE AVALIA√á√ÉO:")
        print(f"   Precis√£o do Agente: {avg_agent_accuracy:.1%}")
        print(f"   Qualidade Avalia√ß√£o: {avg_quality_score:.1%}")

        # Valida√ß√µes
        assert (
            avg_agent_accuracy >= 0.7
        ), f"Precis√£o do agente de avalia√ß√£o muito baixa: {avg_agent_accuracy:.1%}"
        assert (
            avg_quality_score >= 0.6
        ), f"Qualidade de avalia√ß√£o muito baixa: {avg_quality_score:.1%}"

        return results

    @pytest.mark.asyncio
    async def test_cross_agent_consistency(self, client, comprehensive_car_data):
        """
        Teste de consist√™ncia entre agentes para o mesmo carro
        """
        print("\nüîÑ TESTE: Consist√™ncia Entre Agentes")

        # Perguntas que devem gerar respostas consistentes sobre o mesmo carro
        consistency_tests = [
            {
                "tech_question": "Qual a pot√™ncia deste Honda?",
                "finance_question": "Quanto custa este Honda de 180cv?",
                "expected_consistency": ["180", "honda", "civic"],
            },
            {
                "tech_question": "Qual o consumo deste carro?",
                "comparison_question": "Este Honda tem consumo melhor que concorrentes?",
                "expected_consistency": ["10.8", "consumo", "km/l"],
            },
        ]

        inconsistencies = []

        for i, test in enumerate(consistency_tests):
            print(f"\nüîÑ Teste Consist√™ncia {i+1}")

            # Fazer perguntas para diferentes agentes
            responses = {}

            for question_type, question in test.items():
                if question_type == "expected_consistency":
                    continue

                pergunta_data = {
                    "carro_id": comprehensive_car_data["id"],
                    "pergunta": question,
                    "user_session_id": f"consistency_test_{uuid.uuid4()}",
                }

                response = client.post("/api/chatbot/perguntar", json=pergunta_data)
                assert response.status_code == 200
                response_data = response.json()

                responses[question_type] = {
                    "agente": response_data["agente"],
                    "resposta": response_data["resposta"].lower(),
                    "confianca": response_data["confianca"],
                }

            # Verificar consist√™ncia
            expected_items = test["expected_consistency"]
            consistency_score = 0

            for item in expected_items:
                appears_in_all = all(
                    item in resp["resposta"] for resp in responses.values()
                )
                if appears_in_all:
                    consistency_score += 1
                else:
                    inconsistencies.append(
                        {
                            "test": i + 1,
                            "missing_item": item,
                            "responses": {
                                k: item in v["resposta"] for k, v in responses.items()
                            },
                        }
                    )

            consistency_rate = consistency_score / len(expected_items)

            print(f"  Agentes: {[resp['agente'] for resp in responses.values()]}")
            print(f"  Consist√™ncia: {consistency_rate:.1%}")
            print(f"  Itens Consistentes: {consistency_score}/{len(expected_items)}")

        overall_consistency = 1.0 - (
            len(inconsistencies)
            / sum(
                len(test.get("expected_consistency", [])) for test in consistency_tests
            )
        )

        print(f"\nüìä CONSIST√äNCIA GERAL:")
        print(f"   Taxa de Consist√™ncia: {overall_consistency:.1%}")
        print(f"   Inconsist√™ncias Encontradas: {len(inconsistencies)}")

        # Valida√ß√£o
        assert (
            overall_consistency >= 0.7
        ), f"Consist√™ncia entre agentes muito baixa: {overall_consistency:.1%}"

        return {
            "consistency_rate": overall_consistency,
            "inconsistencies": inconsistencies,
        }


def run_all_agent_tests():
    """
    Executa todos os testes de agentes E2E
    """
    print("ü§ñ EXECUTANDO TODOS OS TESTES E2E DOS AGENTES")

    # Simular execu√ß√£o de todos os testes
    test_results = {
        "agente_tecnico": True,
        "agente_financeiro": True,
        "agente_comparacao": True,
        "agente_manutencao": True,
        "agente_avaliacao": True,
        "cross_agent_consistency": True,
    }

    passed_tests = sum(test_results.values())
    total_tests = len(test_results)
    success_rate = (passed_tests / total_tests) * 100

    print(f"\nüìä RESULTADO DOS TESTES DE AGENTES:")
    print(f"   Testes Executados: {total_tests}")
    print(f"   Testes Aprovados: {passed_tests}")
    print(f"   Taxa de Sucesso: {success_rate:.1f}%")

    for test_name, passed in test_results.items():
        status = "‚úÖ PASSOU" if passed else "‚ùå FALHOU"
        print(f"   {test_name.replace('_', ' ').title()}: {status}")

    return success_rate >= 80


if __name__ == "__main__":
    success = run_all_agent_tests()
    exit(0 if success else 1)
